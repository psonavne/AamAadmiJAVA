# OpenAI API Key
# Replace YOUR_OPENAI_API_KEY with your actual OpenAI API Key
# For production, consider using environment variables like: spring.ai.openai.api-key=${OPENAI_API_KEY}
spring.ai.openai.api-key=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

# You can specify the default chat model to use. gpt-4o is powerful, gpt-3.5-turbo is more cost-effective.
# spring.ai.openai.chat.options.model=gpt-4o
spring.ai.openai.chat.options.model=gpt-3.5-turbo

# Configuration for the Vector Store (initially a simple in-memory one)
# This will be automatically configured by Spring AI if you include the starter
# and don't specify a more complex persistent one.
# For demonstration purposes, no explicit configuration is needed for SimpleVectorStore.

# Spring Boot application name
spring.application.name=knowledge-chatbot-backend

# For file uploads (optional, but good for larger files)
spring.servlet.multipart.max-file-size=15MB
spring.servlet.multipart.max-request-size=15MB

# ChromaDB Collection Configuration
spring.ai.vectorstore.chroma.initialize-schema=true
spring.ai.vectorstore.chroma.collection-name=cricket-knowledge

# Ollama Configuration for Chat
#spring.ai.ollama.chat.enabled=true
#spring.ai.ollama.chat.options.model=gemma3

# Ollama Configuration for Embeddings (using gemma3.5 as embedding model)
#spring.ai.ollama.embedding.enabled=true
#spring.ai.ollama.embedding.options.model=mxbai-embed-large
#spring.ai.ollama.base-url=http://localhost:11434


# RAG Prompt Template for ChatService
app.rag.prompt-template=\
    You are a helpful cricket expert chatbot.\n\
    Use the following pieces of context to answer the user's question.\n\
    If you don't know the answer, just say that you don't know, don't try to make up an answer.\n\
    ---------------------\n\
    Context:\n\
    {context}\n\
    ---------------------\n\
    Question: {question}